{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segement Me If U Can\n",
    "THUCST Intro to AI PA 2\n",
    "[Eren zhao](https://zhaochenyang20.github.io/) Class 06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 任务简介\n",
    "- 进行一次情感二分类，仅考虑正负情感。\n",
    "\n",
    "## 实验数据\n",
    "- 实验数据包括包含训练、验证、测试集合以及预处理好的词向量\n",
    "- 句子的分类包含正向和负向两种\n",
    "\n",
    "## 实验要求\n",
    "- 本次实验要求实现 CNN 与 RNN 两个模型，并应用在情感分类任务上。RNN 可以是 LSTM，GRU 等类型。\n",
    "- 对比两模型的实验效果，并分析原因。 也可以实现其他模型作为对比模型（baseline），例如全连接神经网络（MLP），可适当加分。\n",
    "\n",
    "## 评价指标\n",
    "1. 准确率（Accuracy）\n",
    "2. [F-score](https://deepai.org/machine-learning-glossary-and-terms/f-score)，类似 MIOU\n",
    "\n",
    "## 报告内容\n",
    "1. 模型的结构图，以及流程分析。\n",
    "2. 实验结果，准确率，F-score标的实验效果。\n",
    "3. 试简要地比较实验中使用的不同参数效果，并分析原因。\n",
    "4. 比较baseline模型与CNN，RNN模型的效果差异。（如果有实现）\n",
    "5.  问题思考，心得体会\n",
    "\n",
    "## Question List\n",
    "1. 实验训练什么时候停止是最合适的？简要陈述你的实现方式，并试分析固定迭代次数与通过验证集调整等方法的优缺点。\n",
    "2. 实验参数的初始化是怎么做的？不同的方法适合哪些地方？（现有的初始化方法为零均值初始化，高斯分布初始化，正交初始化等）\n",
    "3. 过拟合是深度学习常见的问题，有什么方法可以方式训练过程陷入过拟合\n",
    "4. 试分析CNN，RNN，全连接神经网络（MLP）三者的优缺点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型结构\n",
    "\n",
    "## LSTM\n",
    "\n",
    "![LSTM](https://zhaochenyang20.github.io/pic/lecture/2022_spring/IAI/LSTM.jpg)\n",
    "\n",
    "- 双向 LSTM 分类网络的模型结果如上图。前向传播的流程为：将一批长度统一且标记化的句子输入网络，依次经过：\n",
    "1. 嵌入层：将每个表示单词的自然数映射为指定长度的向量，即用向量表示单词。\n",
    "2. 双向双层 LSTM 层：接收某个 batch 的词向量组成的序列，每个 LSTM 单元在两个方向上分别产生自己的隐藏状态。最终只用了最后一层（第二层）两个方向上传播的各自的最后一个单元的隐藏状态作为下一层的输入。\n",
    "3. 线性分类层：由两层网络构成，接收上述 LSTM 层产生的两个隐藏状态直接拼接起来的向量（维数变为隐藏状态维数的 2 倍）作为输入，经过两层线性层输出维数等于分类类别数的向量，表示对类别的预测结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text-CNN\n",
    "\n",
    "![CNN](https://zhaochenyang20.github.io/pic/lecture/2022_spring/IAI/CNN.jpg)\n",
    "\n",
    "- 依据[参考文献](https://arxiv.org/abs/1408.5882)中的模型搭建 Text-CNN 模型。前向传播流程如下：\n",
    "1. 嵌入层：将每个表示单词的自然数映射为指定长度的向量，即用向量表示单词。\n",
    "2. 一维多通道多卷积核卷积层：将嵌入层得到的数据视为一批多通道的一维张量；一维张量的长度为对齐后的句子长度，通道数为词向量的数。用指定数量与大小的卷积核与输入数据做多通道多卷积核卷积，得到多通道的一维输出特征。用宽度为2、4、8的卷积核分别做三次卷积。\n",
    "3. 池化层：对卷积结果进行 activate, Dropout, max pooling。\n",
    "4. 线性层：将池化后的卷积结果拼接在一起，得到长度为所有卷积输出通道数之和的张量，再经过一层线性层得到表示类别标签预测的向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP\n",
    "\n",
    "![MLP](https://zhaochenyang20.github.io/pic/lecture/2022_spring/IAI/MLP.jpg)\n",
    "\n",
    "使用 MLP 作为 baseline 。模型示意图如上，前向传播大致流程如下：\n",
    "1. 嵌入层：将每个表示单词的自然数映射为指定长度的向量，即用向量表示单词。\n",
    "2. 线性层1：接收一批将句子中的词向量直接拼接起来得到的张量为输入，输出指定大小的张量，然后进行 Batch Normalization, Activation, Dropout。\n",
    "3. 线性层2：输出表示类别标签预测的向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [BERT](https://zhaochenyang20.github.io/pdf/BERT.pdf)\n",
    "借助大型预训练模型 BERT 完成文本分类这一下游任务。模型结构和前向传播方式是：将句子输入 BERT ，取出 BERT 的第一个输出，是一个高维维的向量；将此向量输入一个线性层，得到最终表示分类的向量。\n",
    "可以发现，由于 BERT 已经在海量数据中训练，较好地学习到了词汇的语义，最终在此任务上只需要最后加一个简单的线性层做分类就能达到很好的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 配置信息\n",
    "## 环境库\n",
    "参考 requirements.txt\n",
    "## 可视化\n",
    "采用 [wandb](https://wandb.ai/site) 辅助可视化\n",
    "## 算力\n",
    "由于我自己的电脑是 Macbook M1 Core，虽然 M1 芯片优化了 CPU 计算的性能，然而没有显卡是硬伤。于是我在自己的服务器上进行训练，服务器有 1 张 3080。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1qtnrvkv) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ddff89d5cd4314ade401036884468e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁▁▇█████████████████████████████████████</td></tr><tr><td>train_loss</td><td>██▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▆██▇▇▇████████████████████████████████</td></tr><tr><td>val_loss</td><td>▂▁▂▅▆▆▇▇▇▆▇█▇▆▆▇▇▆▇▆▆▆▇▇▇▇▇█▆█▇▇▇▆▆▆▆▇█▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>0.99825</td></tr><tr><td>train_loss</td><td>0.01063</td></tr><tr><td>val_acc</td><td>0.8374</td></tr><tr><td>val_loss</td><td>0.84605</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">young-vortex-12</strong>: <a href=\"https://wandb.ai/eren-zhao/IAI%202022%20CNN/runs/1qtnrvkv\" target=\"_blank\">https://wandb.ai/eren-zhao/IAI%202022%20CNN/runs/1qtnrvkv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220515_090457-1qtnrvkv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1qtnrvkv). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/work/eren/segmentation/wandb/run-20220515_094339-27rhbuo4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/eren-zhao/IAI%202022%20CNN/runs/27rhbuo4\" target=\"_blank\">fiery-totem-13</a></strong> to <a href=\"https://wandb.ai/eren-zhao/IAI%202022%20CNN\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gensim\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from collections import Counter\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "from torch.optim.lr_scheduler import *\n",
    "from typing import List, Dict\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "wandb.init(project=\"IAI 2022 CNN\", entity=\"eren-zhao\")\n",
    "\n",
    "wandb.config = {\n",
    "  \"learning_rate\": 0.001,\n",
    "  \"epochs\": 100,\n",
    "  \"batch_size\": 50\n",
    "}\n",
    "\n",
    "def getFileList(filePath:str) -> List[str]:\n",
    "    \"\"\"\n",
    "    return dataSet file list except the test file\n",
    "    \"\"\"\n",
    "    files = os.listdir(filePath)\n",
    "    returnList = []\n",
    "    for each in files:\n",
    "        if each.endswith('.txt') and not each.startswith('valid'):\n",
    "            returnList.append(Path.cwd() / filePath / each)\n",
    "    return returnList\n",
    "\n",
    "def getFile(filePath:str, fileName:str) -> str:\n",
    "    \"\"\"\n",
    "    return a specific file from dataSet\n",
    "    \"\"\"\n",
    "    files = os.listdir(filePath)\n",
    "    for each in files:\n",
    "        if each.startswith(f'{fileName}'):\n",
    "            return Path.cwd() / filePath / each\n",
    "\n",
    "def getWord2Id() -> Dict:\n",
    "    \"\"\"\n",
    "    word2id: word -> id\n",
    "    is a dictionary which give each word in training set and valid set a id, range from 0 to n_words\n",
    "    \"\"\"\n",
    "    path = getFileList('Dataset')\n",
    "    word2id = Counter()\n",
    "    for each in path:\n",
    "        with open(each, encoding='utf-8', errors=\"ignore\") as f:\n",
    "            for line in f.readlines():\n",
    "                sentence = line.strip().split()\n",
    "                for word in sentence[1:]:\n",
    "                    if word not in word2id.keys():\n",
    "                        word2id[word] = len(word2id)\n",
    "    return word2id\n",
    "\n",
    "\n",
    "def getWord2Vec(filename, word2id):\n",
    "    \"\"\"\n",
    "    word2vec: word -> vector\n",
    "    is a dictionary which give each word in training set and valid set a vector, range, the length of vector is 50\n",
    "    \"\"\"\n",
    "    path = getFile(\"Dataset\", filename)\n",
    "    preModel = gensim.models.KeyedVectors.load_word2vec_format(path, binary=True)\n",
    "    word2vecs = np.array(np.zeros([len(word2id) + 1, preModel.vector_size]))\n",
    "    for key in word2id:\n",
    "        try:\n",
    "            word2vecs[word2id[key]] = preModel[key]\n",
    "        except Exception:\n",
    "            pass\n",
    "    return word2vecs\n",
    "\n",
    "def getCorpus(path, word2id, maxLength=50):\n",
    "    \"\"\"\n",
    "    :param path: 样本语料库的文件\n",
    "    :return: 文本内容contents，以及分类标签labels(onehot形式)\n",
    "    \"\"\"\n",
    "    contents, labels = np.array([0] * maxLength), np.array([])\n",
    "    with open(path, encoding='utf-8', errors=\"ignore\") as f:\n",
    "        for line in f.readlines():\n",
    "            sentence = line.strip().split()\n",
    "            content = np.asarray([word2id.get(w, 0) for w in sentence[1:]])[:maxLength]\n",
    "            padding = max(maxLength - len(content), 0)\n",
    "            content = np.pad(content, ((0, padding)), 'constant', constant_values=0)\n",
    "            labels = np.append(labels, int(sentence[0]))\n",
    "            contents = np.vstack([contents, content])\n",
    "    contents = np.delete(contents, 0, axis=0)\n",
    "    return contents, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001      # 学习率     \n",
    "BATCH_SIZE = 50            # 训练批量\n",
    "EPOCHS = 10                  # 训练轮数\n",
    "model_path = None          # 预训练模型路径\n",
    "max_length = 50            # 每个样本的最大长度\n",
    "\n",
    "word2id = getWord2Id()\n",
    "word2vec = getWord2Vec('wiki', word2id)\n",
    "train_contents, train_labels = getCorpus('./Dataset/train.txt', word2id, maxLength=max_length)\n",
    "val_contents, val_labels = getCorpus('./Dataset/validation.txt', word2id, maxLength=max_length)\n",
    "test_contents, test_labels = getCorpus('./Dataset/test.txt', word2id, maxLength=max_length)\n",
    "\n",
    "class CONFIG():\n",
    "    update_w2v = True           # 是否在训练中更新w2v\n",
    "    vocab_size = len(word2id) + 1          # 词汇量，与word2id中的词汇量一致\n",
    "    n_class = 2                 # 分类数：分别为pos和neg\n",
    "    embedding_dim = 50          # 词向量维度\n",
    "    drop_keep_prob = 0.3        # dropout层，参数keep的比例\n",
    "    kernel_num = 20            # 卷积层filter的数量\n",
    "    kernel_size = [3, 5, 7]       # 卷积核的尺寸\n",
    "    pretrained_embed = word2vec # 预训练的词嵌入模型\n",
    "    hidden_size = 100           # 隐藏层神经元数\n",
    "    num_layers = 2               # 隐藏层数\n",
    "\n",
    "config = CONFIG()          # 配置模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(TextCNN, self).__init__()\n",
    "        update_w2v = config.update_w2v\n",
    "        vocab_size = config.vocab_size\n",
    "        n_class = config.n_class\n",
    "        embedding_dim = config.embedding_dim\n",
    "        kernel_num = config.kernel_num\n",
    "        kernel_size = config.kernel_size\n",
    "        drop_keep_prob = config.drop_keep_prob\n",
    "        pretrained_embed = config.pretrained_embed\n",
    "        \n",
    "        # 使用预训练的词向量\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        #! embedding is a table, which is used to lookup the embedding vector of a word\n",
    "        self.embedding.weight.requires_grad = update_w2v\n",
    "        #! if update_w2v is True, the embedding.weight will be updated during training\n",
    "        self.embedding.weight.data.copy_(torch.from_numpy(pretrained_embed))\n",
    "        #! import the pretrained embedding vector as embedding.weight\n",
    "\n",
    "\n",
    "        # 卷积层\n",
    "        self.conv1 = nn.Conv2d(1, kernel_num, (kernel_size[0], embedding_dim))\n",
    "        #! conv1 is a convolutional layer, which takes input layer 1 ( we often take picture for 3 layer, but here is the sentence, we take 1 layer)\n",
    "        #! kernel_num is the number of filter, which is the number of output channel, here we have 20 filter\n",
    "        #! every filter bite a matrix of size (3, 50)\n",
    "        self.conv2 = nn.Conv2d(1, kernel_num, (kernel_size[1], embedding_dim))\n",
    "        self.conv3 = nn.Conv2d(1, kernel_num, (kernel_size[2], embedding_dim))\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(drop_keep_prob)\n",
    "        # 全连接层\n",
    "        self.fc = nn.Linear(len(kernel_size) * kernel_num, n_class)\n",
    "\n",
    "    @staticmethod\n",
    "    def conv_and_pool(x, conv):\n",
    "        x = conv(x)\n",
    "        x = F.relu(x.squeeze(3))\n",
    "        x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x.to(torch.int64)).unsqueeze(1)\n",
    "        x1 = self.conv_and_pool(x, self.conv1)  \n",
    "        x2 = self.conv_and_pool(x, self.conv2)  \n",
    "        x3 = self.conv_and_pool(x, self.conv3)\n",
    "        x = F.log_softmax(self.fc(self.dropout(torch.cat((x1, x2, x3), 1))), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "       \n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        vocab_size = config.vocab_size\n",
    "        embedding_dim = config.embedding_dim\n",
    "        pretrained_embed = config.pretrained_embed\n",
    "        self.num_layers = config.num_layers\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.n_class = config.n_class\n",
    "        update_w2v = config.update_w2v\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        #! embedding is a table, which is used to lookup the embedding vector of a word\n",
    "        self.embedding.weight.requires_grad = update_w2v\n",
    "        #! if update_w2v is True, the embedding.weight will be updated during training\n",
    "        self.embedding.weight.data.copy_(torch.from_numpy(pretrained_embed))\n",
    "        #! import the pretrained embedding vector as embedding.weight\n",
    "\n",
    "        # (seq_len, batch, embed_dim) -> (seq_len, batch, 2 * hidden_size)\n",
    "        self.encoder = nn.LSTM(input_size=embedding_dim,\n",
    "                               hidden_size=self.hidden_size,\n",
    "                               num_layers=self.num_layers,\n",
    "                               bidirectional=True)\n",
    "        # (batch, hidden_size * 2) -> (batch, num_classes)\n",
    "        self.decoder = nn.Linear(2 * self.hidden_size, 64)\n",
    "        self.fc1 = nn.Linear(64, self.n_class)\n",
    "        # (batch, num_classes) -> (batch, num_classes)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        \n",
    "        inputs = inputs.to(torch.int64)\n",
    "        x = self.embedding(inputs)             # (batch_size, seq_len, embed_dim)\n",
    "        x = x.permute(1, 0, 2)        # (seq_len, batch_size, embed_dim)\n",
    "        _, (h_n, _) = self.encoder(x)          # (num_layers * 2, batch, hidden_size)\n",
    "        # view h_n as (num_layers, num_directions, batch, hidden_size)\n",
    "        h_n = h_n.view(self.num_layers, 2, -1, self.hidden_size)\n",
    "        h_n = torch.cat((h_n[-1, 0], h_n[-1, 1]), dim=-1) # (batch, hidden_size * 2)\n",
    "        outputs = self.decoder(h_n)                     # (batch, num_classes)\n",
    "        outputs = self.fc1(outputs)\n",
    "       \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "train_dataset = TensorDataset(torch.from_numpy(train_contents).type(torch.float), \n",
    "                              torch.from_numpy(train_labels).type(torch.long))\n",
    "train_dataloader = DataLoader(dataset = train_dataset, batch_size = BATCH_SIZE, \n",
    "                              shuffle = True, num_workers = 2)\n",
    "\n",
    "val_dataset = TensorDataset(torch.from_numpy(val_contents).type(torch.float), \n",
    "                              torch.from_numpy(val_labels).type(torch.long))\n",
    "val_dataloader = DataLoader(dataset = val_dataset, batch_size = BATCH_SIZE, \n",
    "                              shuffle = True, num_workers = 2)\n",
    "\n",
    "test_dataset = TensorDataset(torch.from_numpy(test_contents).type(torch.float), \n",
    "                              torch.from_numpy(test_labels).type(torch.long))\n",
    "test_dataloader = DataLoader(dataset = test_dataset, batch_size = BATCH_SIZE, \n",
    "                              shuffle = True, num_workers = 2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/root/miniconda3/envs/torch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:371: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      " 10%|█         | 1/10 [00:05<00:47,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for epoch 1, train_loss: 0.4942, train_acc: 0.7586, val_loss: 0.4490, val_acc: 0.8157, learning_rate: [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:10<00:42,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for epoch 2, train_loss: 0.3264, train_acc: 0.8686, val_loss: 0.3720, val_acc: 0.8537, learning_rate: [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:15<00:36,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for epoch 3, train_loss: 0.2184, train_acc: 0.9201, val_loss: 0.5894, val_acc: 0.7859, learning_rate: [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:20<00:31,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for epoch 4, train_loss: 0.1374, train_acc: 0.9535, val_loss: 0.4824, val_acc: 0.8130, learning_rate: [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:26<00:26,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for epoch 5, train_loss: 0.0852, train_acc: 0.9733, val_loss: 0.5187, val_acc: 0.8320, learning_rate: [1e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:31<00:20,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for epoch 6, train_loss: 0.0346, train_acc: 0.9912, val_loss: 0.7483, val_acc: 0.8401, learning_rate: [0.0001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:36<00:15,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for epoch 7, train_loss: 0.0301, train_acc: 0.9928, val_loss: 0.7204, val_acc: 0.8238, learning_rate: [0.0001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:41<00:10,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for epoch 8, train_loss: 0.0263, train_acc: 0.9939, val_loss: 0.7484, val_acc: 0.8320, learning_rate: [0.0001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:46<00:05,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for epoch 9, train_loss: 0.0228, train_acc: 0.9948, val_loss: 0.7413, val_acc: 0.8374, learning_rate: [0.0001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:52<00:00,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for epoch 10, train_loss: 0.0206, train_acc: 0.9952, val_loss: 0.8012, val_acc: 0.8211, learning_rate: [1.0000000000000002e-06]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = RNN(config).to(DEVICE)\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# 设置损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = StepLR(optimizer, step_size=5)\n",
    "\n",
    "\n",
    "def train(dataloader,epoch):\n",
    "    # 定义训练过程\n",
    "    model.train()\n",
    "    train_loss,train_acc = 0.0,0.0\n",
    "    count, correct = 0,0\n",
    "    for _, (x, y) in enumerate(dataloader):\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        correct += (output.argmax(1) == y).float().sum().item()\n",
    "        count += len(x)\n",
    "                            \n",
    "    train_loss *= BATCH_SIZE\n",
    "    train_loss /= len(dataloader.dataset)\n",
    "    train_acc = correct/count\n",
    "    scheduler.step()\n",
    "    \n",
    "    return train_loss,train_acc\n",
    "\n",
    "\n",
    "def validation(dataloader):\n",
    "    model.eval()\n",
    "    # 验证过程\n",
    "    val_loss,val_acc = 0.0,0.0\n",
    "    count, correct = 0,0\n",
    "    for _, (x, y) in enumerate(dataloader):\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        val_loss += loss.item()\n",
    "        correct += (output.argmax(1) == y).float().sum().item()\n",
    "        count += len(x)\n",
    "    \n",
    "    val_loss *= BATCH_SIZE\n",
    "    val_loss /= len(dataloader.dataset)\n",
    "    val_acc = correct/count\n",
    "    \n",
    "    return val_loss,val_acc\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(1,EPOCHS+1)):\n",
    "    tr_loss,tr_acc = train(train_dataloader, epoch)\n",
    "    val_loss,val_acc = validation(test_dataloader)\n",
    "    wandb.log({\"train_loss\": tr_loss, \"train_acc\": tr_acc, \"val_loss\": val_loss, \"val_acc\": val_acc, \"learning_rate\": scheduler.get_lr()})\n",
    "    print(f\"for epoch {epoch}, train_loss: {tr_loss:.4f}, train_acc: {tr_acc:.4f}, val_loss: {val_loss:.4f}, val_acc: {val_acc:.4f}, learning_rate: {scheduler.get_lr()}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f64be793538f7fe230f350828c9baf03d97c4df0981f52e8388f53f367f4a42"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
